{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Using ChatGPT as a writing assistant of English for Research Publication Purposes (ERPP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2af7-9fc1-4f51-a4f5-2ed915b93039",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4a8657-0245-4eaf-b11f-233891dc8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from os import environ\n",
    "import datetime as dt\n",
    "from google.cloud import translate\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb712a-9e8d-488c-a1ea-d06db3f68a56",
   "metadata": {},
   "source": [
    "## Setting the required environment variables in the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256e6a2-529d-4d08-b491-c36e4be1ab22",
   "metadata": {},
   "source": [
    "Please refer to [Setting environment variables](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#setting-environment-variables) on [Managing environments](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#).\n",
    "\n",
    "Note: Do **not** place the value of the variables between ' ' or \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10745631-6187-4083-8f0a-45766f0653c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(base) C:\\Users\\eyamr>conda env list\n",
    "# conda environments:\n",
    "#\n",
    "base                  *  C:\\Users\\eyamr\\anaconda3\n",
    "Env20240401              C:\\Users\\eyamr\\anaconda3\\envs\\Env20240401\n",
    "\n",
    "\n",
    "(base) C:\\Users\\eyamr>conda activate Env20240401\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda env config vars list\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda env config vars set GOOGLE_CLOUD_PROJECT=<omitted>\n",
    "To make your changes take effect please reactivate your environment\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda env config vars set OPENAI_API_KEY=<omitted>\n",
    "To make your changes take effect please reactivate your environment\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda activate Env20240401\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda env config vars list\n",
    "GOOGLE_CLOUD_PROJECT = <omitted>\n",
    "OPENAI_API_KEY = <omitted>\n",
    "\n",
    "(Env20240401) C:\\Users\\eyamr>conda deactivate\n",
    "\n",
    "(base) C:\\Users\\eyamr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbdcb83-4f20-4fcc-81be-b79d919f0e05",
   "metadata": {},
   "source": [
    "## Importing the required programme variables from the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c170f9-c4e4-41bf-be38-798c0e36aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = environ.get('OPENAI_API_KEY', '')\n",
    "assert openai.api_key\n",
    "GOOGLE_CLOUD_PROJECT = environ.get('GOOGLE_CLOUD_PROJECT', '')\n",
    "assert GOOGLE_CLOUD_PROJECT\n",
    "GOOGLE_CLOUD_PROJECT = str(GOOGLE_CLOUD_PROJECT)\n",
    "PARENT = f'projects/{GOOGLE_CLOUD_PROJECT}'\n",
    "#print(openai.api_key)\n",
    "#print(GOOGLE_CLOUD_PROJECT)\n",
    "#print(PARENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f419e-d55d-4fde-befd-3bac85506783",
   "metadata": {},
   "source": [
    "## Defining a function to translate passages with Google Cloud Translation API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecbd8c-b617-4663-b06f-77f4acc5cc27",
   "metadata": {},
   "source": [
    "Application Default Credentials (ADC) should be configured in order to authenticate the use of Google Cloud Translation API - follow the procedure indicated in [Set up authentication for Cloud Translation](https://cloud.google.com/translate/docs/authentication#authn-how-to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc4c45d-e81f-4a78-891d-7ed1433a7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text: str, target_language_code: str) -> translate.Translation:\n",
    "    client = translate.TranslationServiceClient()\n",
    "    response = client.translate_text(\n",
    "        parent = PARENT,\n",
    "        contents = [text],\n",
    "        target_language_code = target_language_code\n",
    "    )\n",
    "    return response.translations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a92f39-e319-465a-bcbd-6cafee548a8b",
   "metadata": {},
   "source": [
    "## Defining a function to query ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1facf05-20f9-4c27-866d-39e2d0642f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model = 'gpt-3.5-turbo'):\n",
    "    client = openai.OpenAI()\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = 0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002841de-71a4-47bf-b0d1-d53b749395d7",
   "metadata": {},
   "source": [
    "## Collecting input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef7395-f79e-40ae-befd-cf02626c7132",
   "metadata": {},
   "source": [
    "Note: Pandas raises the following data type warning (DtypeWarning) when data is cast to an incompatible data typeL'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06517e-09ff-47ac-a05c-d12fb8d2d607",
   "metadata": {},
   "source": [
    "FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'In the field of Corpus Linguistics ...' has dtype incompatible with float64, please explicitly cast to a compatible dtype first\r\n",
    "\r\n",
    "df_text.at[index, 'composed'] = query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2fd73-f8bd-4559-b5c9-2318df63f72d",
   "metadata": {},
   "source": [
    "Refer to the following references to learn how to handle it:\n",
    "- [pandas.errors.DtypeWarning](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.errors.DtypeWarning.html)\n",
    "- [Pandas DtypeWarning: Columns have mixed types](https://www.slingacademy.com/article/pandas-dtypewarning-columns-have-mixed-types/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd2d127-3dc9-4c5c-9efa-2a5f77623e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 set(s) of notes to process.\n"
     ]
    }
   ],
   "source": [
    "end = False\n",
    "while end == False:\n",
    "    filename = str(input('Enter the input full filename: '))\n",
    "    if filename != '':\n",
    "        try:\n",
    "            with open(filename, 'r', encoding = 'utf8', newline='\\n') as responses:\n",
    "                print('The file exists.')\n",
    "            input_file = filename\n",
    "            output_file = input_file + '.out.txt'\n",
    "            output_file_json = input_file + '.out.json'\n",
    "            end = True\n",
    "            clear_output()\n",
    "        except FileNotFoundError:\n",
    "            print('No such file.')\n",
    "df_text = pd.read_table(input_file, sep = '\\\\n', header = None, engine = 'python')\n",
    "df_text = df_text.rename(columns = {0: 'notes'})\n",
    "df_text.at[0, 'ai_composed'] = 1 # Adding column 'ai_composed' by initialising it with a numeric value in order to avoid DtypeWarning\n",
    "df_text.at[0, 'human_revised'] = 1\n",
    "df_text.at[0, 'ai_translated'] = 1\n",
    "df_text = df_text.astype('object') # Converting the column to the desired data type\n",
    "print(str(len(df_text)) + ' set(s) of notes to process.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2673b2-53fe-45c8-8fae-f9bef3c5cbbe",
   "metadata": {},
   "source": [
    "## Composing with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb65dca-9fee-4feb-b075-d4d9ff9b9b89",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c879411-1708-4ef7-8e7b-be7e256d02db",
   "metadata": {},
   "source": [
    "Dear ChatGPT, please write a piece of academic text based on the following notes considering the generally accepted standards of English for Academic Purposes. It is very important that you are as objective, scientific and non-metaphorical as you can be.\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c8336-7235-47ca-87fd-9e2b0a1bc61e",
   "metadata": {},
   "source": [
    "### Composing with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99a4d13-83a6-4a1e-82c8-05d37b56e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>ai_composed</th>\n",
       "      <th>human_revised</th>\n",
       "      <th>ai_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Lexical Multi-Dimensional Analysis (LMD An...</td>\n",
       "      <td>The Lexical Multi-Dimensional Analysis (LMD An...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               notes  \\\n",
       "0  The Lexical Multi-Dimensional Analysis (LMD An...   \n",
       "\n",
       "                                         ai_composed human_revised  \\\n",
       "0  The Lexical Multi-Dimensional Analysis (LMD An...           1.0   \n",
       "\n",
       "  ai_translated  \n",
       "0           1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(output_file, 'a', encoding = 'utf8', newline='\\n') as responses:\n",
    "    responses.write('ChatGPT ERPP writing assistant' + '\\n\\n')\n",
    "    responses.write('Start time: ' + str(dt.datetime.now()) + '\\n\\n')\n",
    "    prompt = 'Dear ChatGPT, please write a piece of academic text based on the following notes considering the generally accepted standards of English for Academic Purposes. It is very important that you are as objective, scientific and non-metaphorical as you can be.\\n'\n",
    "    for index, row in df_text.iterrows():\n",
    "        responses.write('Notes ' + str(index) + ':\\n' + row['notes'] + '\\n\\n')\n",
    "        print('Notes ' + str(index) + ':\\n' + row['notes'])\n",
    "        query = get_completion(prompt + row['notes'])\n",
    "        df_text.at[index, 'ai_composed'] = query\n",
    "        responses.write('Composed by AI ' + str(index) + ':\\n' + query + '\\n\\n')\n",
    "        print('\\nComposed by AI ' + str(index) + ':\\n' + query)\n",
    "        clear_output(wait = True)\n",
    "    responses.write('End time: ' + str(dt.datetime.now()) + '\\n\\n')\n",
    "print('Job completed!')\n",
    "df_text_json = df_text.to_json()\n",
    "df_text_json_parsed = json.loads(df_text_json)\n",
    "df_text_json_prettified = json.dumps(df_text_json_parsed, indent=4)\n",
    "with open(output_file_json, 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(df_text_json_prettified)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72a57a-c8e2-4c45-9291-d998182d36af",
   "metadata": {},
   "source": [
    "## Revising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31147a-4bec-459a-af19-1c5f1f20a89a",
   "metadata": {},
   "source": [
    "Edit the column `human_revised` output json file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3cf36-133b-4154-ad78-cd493c2a0e0d",
   "metadata": {},
   "source": [
    "## Translating with Google Cloud Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf14c02b-b0a7-4efa-b79d-2390fa3b3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>ai_composed</th>\n",
       "      <th>human_revised</th>\n",
       "      <th>ai_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Lexical Multi-Dimensional Analysis (LMD An...</td>\n",
       "      <td>The Lexical Multi-Dimensional Analysis (LMD An...</td>\n",
       "      <td>The Lexical Multi-Dimensional Analysis (LMD An...</td>\n",
       "      <td>A An치lise Multidimensional Lexical (An치lise LM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               notes  \\\n",
       "0  The Lexical Multi-Dimensional Analysis (LMD An...   \n",
       "\n",
       "                                         ai_composed  \\\n",
       "0  The Lexical Multi-Dimensional Analysis (LMD An...   \n",
       "\n",
       "                                       human_revised  \\\n",
       "0  The Lexical Multi-Dimensional Analysis (LMD An...   \n",
       "\n",
       "                                       ai_translated  \n",
       "0  A An치lise Multidimensional Lexical (An치lise LM...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.read_json(output_file_json) # Update the dataframe with the revised texts\n",
    "target_language = 'pt'\n",
    "with open(output_file, 'a', encoding = 'utf8', newline='\\n') as responses:\n",
    "    responses.write('Translating with Google Cloud Translate' + '\\n\\n')\n",
    "    responses.write('Start time: ' + str(dt.datetime.now()) + '\\n\\n')\n",
    "    for index, row in df_text.iterrows():\n",
    "        responses.write('Human Revised ' + str(index) + ':\\n' + row['human_revised'] + '\\n\\n')\n",
    "        print('Human Revised ' + str(index) + ':\\n' + row['human_revised'])\n",
    "        translation = translate_text(row['human_revised'], target_language)\n",
    "        source_language = translation.detected_language_code\n",
    "        translated_passage = translation.translated_text\n",
    "        df_text.at[index, 'ai_translated'] = translated_passage\n",
    "        responses.write('Translated by AI ' + str(index) + ' from (' + source_language + ')' + ':\\n' + translated_passage + '\\n\\n')\n",
    "        print('\\nTranslated by AI ' + str(index) + ' from (' + source_language + ')' + ':\\n' + translated_passage)\n",
    "        clear_output(wait = True)\n",
    "    responses.write('End time: ' + str(dt.datetime.now()) + '\\n\\n')\n",
    "print('Job completed!')\n",
    "df_text_json = df_text.to_json()\n",
    "df_text_json_parsed = json.loads(df_text_json)\n",
    "df_text_json_prettified = json.dumps(df_text_json_parsed, indent=4)\n",
    "with open(output_file_json, 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(df_text_json_prettified)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57dcf6-e6d7-4098-b306-bfb86dedf5b4",
   "metadata": {},
   "source": [
    "## Translating with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d589e1-db24-4faf-8d8e-389a6587286e",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee0aff-5106-4bfe-aec0-53c3bdb4302a",
   "metadata": {},
   "source": [
    "Dear ChatGPT, please translate the following text into Brazilian Portuguese.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73392f9-d684-4214-afbd-61158c9d9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_json(output_file_json) # Update the dataframe with the revised texts\n",
    "with open(output_file, 'a', encoding = 'utf8', newline='\\n') as responses:\n",
    "    responses.write('Translating with ChatGPT' + '\\n\\n')\n",
    "    responses.write('Start time: ' + str(dt.datetime.now()) + '\\n\\n')\n",
    "    for index, row in df_text.iterrows():\n",
    "        responses.write('Human Revised ' + str(index) + ':\\n' + row['human_revised'] + '\\n\\n')\n",
    "        print('Human Revised ' + str(index) + ':\\n' + row['human_revised'])\n",
    "        prompt = 'Dear ChatGPT, please translate the following text into Brazilian Portuguese.\\n'\n",
    "        query = get_completion(prompt + row['human_revised'])\n",
    "        df_text.at[index, 'ai_translated'] = query\n",
    "        responses.write('Translated by AI ' + str(index) + ':\\n' + query + '\\n\\n')\n",
    "        print('\\nTranslated by AI ' + str(index) + ':\\n' + query)\n",
    "        clear_output(wait = True)\n",
    "    responses.write('End time: ' + str(dt.datetime.now()) + '\\n\\n')\n",
    "print('Job completed!')\n",
    "df_text_json = df_text.to_json()\n",
    "df_text_json_parsed = json.loads(df_text_json)\n",
    "df_text_json_prettified = json.dumps(df_text_json_parsed, indent=4)\n",
    "with open(output_file_json, 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(df_text_json_prettified)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f1086-c468-4389-9d8b-8139082a89cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
